# Linux-ElasticSearch使用手册

## 语句记录

```bash
# (CUST_CERT_CITY = 平凉市 and TRAN_DATE>=2017) 
# and ( PEER_ACCT_NAMESPELL="dengchunbo" or CUST_NAMESPELL like "z*")

GET *-*/_search
{
  "query": {
    "bool": {
      "should": [
        {
          "bool": {
            "must": [
              {
                "term": {
                  "PEER_ACCT_NAMESPELL": "dengchunbo"
                }
              }
            ]
          }
        },
        {
          "bool": {
            "must": [
              {
                "query_string": {
                  "query": "z*",
                  "fields": [
                    "CUST_NAMESPELL"
                  ]
                }
              }
            ]
          }
        }
      ],
      "must": [
        {
          "term": {
            "CUST_CERT_CITY": "平凉市"
          }
        },
        {
          "range": {
            "TRAN_DATE": {
              "gte": "2017-01-01"
            }
          }
        },
        {
          "range": {
            "TRAN_DATE": {
              "lte": "2018-01-01"
            }
          }
        }
      ]
    }
  }
}

# (PEER_ACCT_NAMESPELL="dengchunbo") or 
# (CUST_CERT_CITY="平凉市" and TRAN_DATE>"201701")
GET *-*/_search
{
  "_source": [
    "PEER_ACCT_NAMESPELL",
    "CUST_CERT_CITY"
  ],
  "query": {
    "bool": {
      "should": [
        {
          "bool": {
            "must": [
              {
                "term": {
                  "PEER_ACCT_NAMESPELL": "dengchunbo"
                }
              }
            ]
          }
        },
        {
          "bool": {
            "must": [
              {
                "term": {
                  "CUST_CERT_CITY": "平凉市"
                }
              },
              {
                "range": {
                  "TRAN_DATE": {
                    "gte": "2017-01-01"
                  }
                }
              },
              {
                "range": {
                  "TRAN_DATE": {
                    "lte": "2018-01-01"
                  }
                }
              }
            ]
          }
        }
      ]
    }
  }
}        
```



















# 查询语法

**match和term区别**
- match：模糊匹配。              匹配的时候，会将查询的关键字进行分词，然后根据分词后的结果进行查询。
- term：精确匹配，只匹配和输入字符一样的数据。            直接使用关键字进行查询，不对关键字进行分词。 精确匹配 适合数字日期

**聚合再过滤方法**
post_filter 只能针对agg后的结果再filter 真实值，而不能对聚合后的指标（avg,sum，count）filter，需要使用bucket_selector

```
# https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-pipeline-bucket-selector-aggregation.html

用它实现了如下SQL
select company_id, count(1) from xxx_table where company_id between A and B group by company_id having count(1) > 1;
 
{
  "size": 0,
  "query": {
    "constant_score": {
      "filter": {
        "range": {
          "company_id": {
            "gte": A,
            "lte": B
          }
        }
      }
    }
  },
  "aggs": {
    "count_by_company_id": {
      "terms": {
        "field": "company_id"
      },
      "aggs": {
        "distinct_id": {
          "cardinality": {
            "field": "company_id"
          }
        },
        "id_bucket_filter": {
          "bucket_selector": {
            "buckets_path": {
              "value": "distinct_id"
            },
            "script": "params.value> 1"
          }
        }
      }
    }
  }
}
```


**聚合分页器**
在实际应用中用户的数量非常惊人, 不可能通过一次查询得到全部结果因此我们需要分页器分批取回:
GET /view_log/_search
{
   "size" : 0,
   "query": {
       "range": {
           "time": {
               "gte": 0, // since
               "lte": 0 // to
           }
       }
   },
   "aggs": {
      "agg": { 
        "terms": { 
            "field": "uid",
            "size": 10000, // bucket 的最大个数
            "include": { // 将聚合结果分为10页，序号为[0,9], 取第一页
                "partition": 0,
                "num_partitions": 10 
            }
        },
        "aggs": { 
          "avg_duration": { 
              "avg": { 
                "field": "watch_duration" 
              }
          }
        }
      }
   }
}
上述查询与上节的查询几乎完全相同，只是在aggs.agg.terms字段中添加了include字段进行分页。





```python

# 基本查询用法 - bool
GET /*-2018-01-31/_search
{
  "_source": "CERT_NO", 
  "query": {
    "bool": {
      "filter": {
          "term": {
          "CERT_NO":"6501"
          }
        }
      }
  }
}
```

range过滤 gt-大于 gte-大于等于 lt-小于 lte-小于等于

# 查询笔记 - 未整理


```python

TODO 无法使用
ES查询中，有时候我们需要按照字段的长度过滤。以下为方法：
GET hockey/_search
{
  "query": {
    "script": {
      "script": {
        "source": "doc['city'][0].length()>3",
        "lang": "painless"
      }
    }
  }
}
TODO 无法使用
ES查询中，有时候我们需要按照字段的长度过滤。以下为方法：
GET /*-60001-2018-01-31/_search
{
  "_source": "CUST_NAME", 
  "query": {
    "bool": {
      "filter": {
            "script" : {
              "script" : "doc['CUST_NAME'].value().size() < 9"
            }
        }
      }
  }
}



GET /*-2018-01-31/_search
{
 "_source": "CUST_NAME", 
  "query": {
    "match_all": {}
  }
}

  #"_source": "CERT_NO", 

# 精确前缀匹配 postfix 类似于过滤
GET /*-2018-01-31/_search
{
  "_source": "CERT_NO", 
  "size": 20, 
  "query": {
    "prefix": {
      "CERT_NO": {
        "value": "6501"
      }
    }
  }
}
# 模糊匹配 且
GET /*-2018-01-31/_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "CERT_NO":  "6501" }},
        { "match": { "value": "6532"   }}
      ]
    }
  }
}


# 查询字段长度
GET /*-2018-01-31/_search
{
  "query": {
    "filtered": {
      "query": {
          "match": {
              "title": {
                  "query": "黄晓明和杨颖结婚",
                  "operator": "and",
                  "minimum_should_match": "90%"
              }
          }        
      },
      "filter": {
        "script" : {
            "script" : "doc['CUST_NAME'].size() < 4"
        }
      }
    }
  }
}



GET /nm*/_search
{
  "query": {
    "filtered": {
      "query": {
          "match": {
              "title": {
                  "query": "黄晓明和杨颖结婚",
                  "operator": "and",
                  "minimum_should_match": "90%"
              }
          }        
      },
      "filter": {
        "script" : {
            "script" : "doc['title'].size() < 9"
        }
      }
    }
  }
}
 








GET /*-2018-01-31/_search
{
  "query": {
    "bool": {
      "should": [
               {"match": {
                 "CERT_NO": "6501"
               }
               }

      ]
    }
  }
}

# no [query] registered for [filtered]
# 过滤查询已被弃用，
GET /*-2018-01-31/_search
{
   "query" : {
      "filtered" : {
         "filter" : {
            "bool" : {
              "should" : [
                { "term": { "CERT_NO": "6501" }}

              ]
           }
         }
      }
   }
}


GET /*-60001-2018-01-31/_search
{
  "_source": "CUST_NAME", 
  "query": {
    "bool": {
      "filter": {
            "script" : {
              "script" : "doc['CUST_NAME'].value().size() < 9"
            }
        }
      }
  }
}


GET /*-60001-2018-01-31/_search
{
"query":{
    "script":{
      "script":{
        "source":"doc.length()>3",
        "lang":"painless"
      }
    }
  }
}




GET /*-2018-01-31/_search
{
  "_source": "CERT_NO", 
  "query": {
    "bool": {
      "filter": {
          "term": {
          "CERT_NO":"6501"
          }
        }
      }
  }
}

```








# 模型ES语句


## 模型名称 KZ0001
```python
# 语法说明
# 模型名称 KZ0001
# bool复合过滤器 - must/should/must_not
# should 至少一个语句匹配 类似 or
# prefix 前缀精准匹配，直接使用关键字匹配字符前缀
# 平均耗时 18 20485
GET /*-2018-01-31/_search
{
  "_source": "CERT_NO", 
  "query": {
    "bool": {
      "should": [
        { "prefix": { "CERT_NO": "6501" }},
        { "prefix": { "CERT_NO": "6532" }},
        { "prefix": { "CERT_NO": "6531" }},
        { "prefix": { "CERT_NO": "6524" }},
        { "prefix": { "CERT_NO": "6529" }},
        { "prefix": { "CERT_NO": "6502" }},
        { "prefix": { "CERT_NO": "6530" }},
        { "prefix": { "CERT_NO": "6528" }},
        { "prefix": { "CERT_NO": "6521" }},
        { "prefix": { "CERT_NO": "6527" }}
      ]
    }
  }
}
```

## 模型名称 KZ0002

KZ0002 特定年龄
GET /*-2018-01-31/_search
{
  "_source": "CUST_BIRTHDAY", 
  "query": {
    "range": {
      "CUST_BIRTHDAY": {
        "gte":"19600101",
        "lte": "19901231"
      }
    }
  }
}



## 模型名称 KZ0003
名字长度在 4 个汉字以上 
TODO doc['cust_name']出错
```python
# 由于 doc['cust_name']出错
# 所以采用 CUST_CERTNO
# 运行耗时 73
GET /tranjrnl-60001-2018-01-31/_search
{
  "query": {
    "bool": {
      "filter": {
            "script" : {
              "script" : "doc['CUST_CERTNO'].size() < 10"
            }
        }
      }
  }
}
# 运行耗时 71
GET /custacct-60001-2018-01-31/_search
{
  "query": {
    "bool": {
      "filter": {
            "script" : {
              "script" : "doc['CUST_NO'].size() < 10"
            }
        }
      }
  }
}

269 100W
GET /tranjrnl-60001-2018-01-31/_search
{
  "_source": "CUST_CERTNO", 
  "query": {
    "bool": {
      "filter": {
            "script" : {
              "script" : "doc['CUST_CERTNO'][0].length() > 10"
            }
        }
      }
  }
}
90 200W
GET /custacct-60001-2018-01-31/_search
{
  "_source": "CUST_NO", 
  "query": {
    "bool": {
      "filter": {
            "script" : {
              "script" : "doc['CUST_NO'][0].length() > 10"
            }
        }
      }
  }
}
```



## KZ0004 

一段时间内频繁取现








## KZ0005

一段时间内频繁转账



## KZ0006

TODO KZ0006 一段时间内频繁存现 获取数据条数
```python
# KZ0006 一段时间内频繁存现
# range过滤 gt-大于 gte-大于等于 lt-小于 lte-小于等于
GET /tranjrnl-60001-2018-01-31/_search
{
  "_source": ["TRAN_AMT","CUST_CERTNO"], 
  "query": {
    "range": {
      "TRAN_AMT": {
        "gt": 100
      }
    }
    
  },
  "aggs": {
    "group_by_CUST_CERTNO": {
      "terms": {
        "field": "CUST_CERTNO",
        "size": 10
      }
    }
  }
}
```


## KZ0007
KZ0007 跨境汇入汇款涉及敏感国家
```python
# KZ0007 跨境汇入汇款涉及敏感国家
# TRAN_NET_NATION 交易网点国家
# took 17 total 111026
GET /tranjrnl-60001-2018-01-31/_search
{
  "_source": "TRAN_NET_NATION", 
  "query": {
    "terms": {
      "TRAN_NET_NATION": [
        "美国",
        "土耳其",
        "阿塞拜疆",
        "巴基斯坦",
        "阿富汗",
        "哈萨克斯坦",
        "吉尔吉斯斯坦",
        "乌兹别克斯坦",
        "塔吉克斯坦",
        "马来西亚",
        "泰国",
        "越南",
        "缅甸"
      ]
    }
  }
}
```




## KZ0014 
身份证前2位以65开头

took 9 total 33478

GET /*-2018-01-31/_search
{
  "_source": "CERT_NO", 
  "query": {
    "bool": {
      "should": [
        { "prefix": { "CERT_NO": "65" }}
      ]
    }
  }
}

## KZ00015
10天内存在马来西亚、泰国、越南、土耳其、阿富汗、巴基斯坦、埃及、哈萨克斯坦地区ATM取现，笔数>1
23148 26
```python
GET /tranjrnl-60001-2018-01-31/_search
{
  "size": 1,
  "_source": ["CUST_CERTNO","TRAN_AMT","TRAN_NET_NATION","TRAN_DATE"], 
  "query": {
    "bool": {
      "filter": [
        {
          "terms": {
            "TRAN_NET_NATION": [
              "马来西亚",
              "泰国",
              "越南",
              "土耳其",
              "阿富汗",
              "巴基斯坦",
              "埃及",
              "哈萨克斯坦"
            ]
          }
        },
        {
          "range": {
            "TRAN_DATE": {
              "gte": "2018-01-01",
              "lte": "2018-01-10"
            }
          }
        }
      ]
    }
  },
  "aggs": {
    "view_count": {
      "terms": {
        "field": "CUST_CERTNO"
      },
      "aggs": {
        "having": {
          "bucket_selector": {
            "buckets_path": { 
              "view_count": "_count"
            },
            "script": {
              "source": "params.view_count > 1"
            }
          }
        }
      }
    }
  }
}
```

## Z057006

total 23721 
took 23
```python
GET /*-2018-01-31/_search
{
  "_source": "CERT_NO", 
  "query": {
    "bool": {
      "should": [
        { "prefix": { "CERT_NO": "6501" }},
        { "prefix": { "CERT_NO": "6532" }},
        { "prefix": { "CERT_NO": "6531" }},
        { "prefix": { "CERT_NO": "6524" }},
        { "prefix": { "CERT_NO": "6529" }},
        { "prefix": { "CERT_NO": "6502" }},
        { "prefix": { "CERT_NO": "6530" }},
        { "prefix": { "CERT_NO": "6528" }},
        { "prefix": { "CERT_NO": "6521" }},
        { "prefix": { "CERT_NO": "6527" }},
        { "prefix": { "CERT_NO": "6540" }},
        { "prefix": { "CERT_NO": "6541" }}
      ]
    }
  }
}
```
## Z057007

年龄区间 15-30 岁
GET /*-2018-01-31/_search
{
  "_source": "CUST_BIRTHDAY", 
  "query": {
    "range": {
      "CUST_BIRTHDAY": {
        "gte":"19820101",
        "lte": "20131231"
      }
    }
  }
}


## Z057004
K特定名字客户	姓名长度在 4 个（含）汉字以上
GET /tranjrnl-60001-2018-01-31/_search
{
  "_source": "CUST_CERTNO", 
  "query": {
    "bool": {
      "filter": {
            "script" : {
              "script" : "doc['CUST_NAME'][0].length() > 8"
            }
        }
      }
  }
}

## Z058001 




## TZ0001
监控时间范围: 0101-0110 0111-0112
```python
# took:25 total:800814
GET /tranjrnl-60001-2018-01-31/_search
{
  "_source": "TRAN_DATE", 
  "query": {
    "bool": {
      "should": [
          {
          "range": {
            "TRAN_DATE": {
              "gte": "2018-01-01",
              "lte": "2018-01-10"
              }
            }
          },
          {
          "range": {
            "TRAN_DATE": {
              "gte": "2018-01-11",
              "lte": "2018-01-12"
              }
            }
          }
        ]
      }
    }
  }
}
```

## TZ0002














#### 全文搜素

到目前为止搜索都很简单：搜索特定的名字，通过年龄筛选。让我们尝试一种更高级的搜索，全文搜索——一种传统数据库
很难实现的功能。
默认情况下，Elasticsearch根据结果相关性评分来对结果集进行排序，所谓的「结果相关性评分」就是文档与查询条件的匹
配程度。
相关性(relevance)的概念在Elasticsearch中非常重要

#### 短语搜索（精确匹配）
使用match_phrase代替match即可使用精准匹配
```json
GET /megacorp/employee/_search
{
"query" : {
"match_phrase" : {
"about" : "rock climbing"
}
}
}
```
#### 高亮我们的搜索(highlight)
高亮参数
```
"highlight": {
"fields" : {
"about" : {} # 对应的高亮字段
}
}
```

#### 分析
Elasticsearch有一个功能叫做**聚合(aggregations)**，它允许你在数据上生成复杂的分析统计。它很像SQL中的 GROUP BY 但是功能更强大。

```
GET /megacorp/employee/_search
{
"aggs": {   # 聚合参数
"all_interests": {  # 聚合后名称，自定义
"terms": { "field": "interests" } # 选定的聚合字段
}
}
}
```


#### 分布式特性

Elasticsearch致力于隐藏分布式系统的复杂性。以下这些操作都是在底层自动完成的：
- 将你的文档分区到不同的容器或者分片(shards)中，它们可以存在于一个或多个节点中。
- 将分片均匀的分配到各个节点，对索引和搜索做负载均衡。
- 冗余每一个分片，防止硬件故障造成的数据丢失。
- 将集群中任意一个节点上的请求路由到相应数据所在的节点。
- 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。







## 数据

### 前言
无论程序怎么写，意图是一样的：组织数据为我们的目标所服务。
面向对象编程语言流行的原因之一，是我们可以用对象来表示和处理现实生活中那些有着潜在关系和复杂结构的实体。到目前为止，这种方式还不错。
对象(object)是一种语言相关，记录在内存中的的数据结构。为了在网络间发送，或者存储它，我们需要一些标准的格式来表示它。JSON (JavaScript Object Notation是一种可读的以文本来表示对象的方式。它已经成为NoSQL世界中数据交换的一种事实标准。当对象被序列化为JSON，它就成为JSON文档(JSON document)了。

Elasticsearch是一个分布式的文档(document)存储引擎。它可以实时存储并检索复杂数据结构——序列化的JSON文档。换言说，一旦文档被存储在Elasticsearch中，它就可以在集群的任一节点上被检索。

在Elasticsearch中，每一个字段的数据都是默认被索引的。也就是说，每个字段专门有一个反向索引用于快速检索。而且，与其它数据库不同，它可以在同一个查询中利用所有的这些反向索引，以惊人的速度返回结果。

### 文档

#### 文档的定义
程序中大多的实体或对象能够被序列化为包含键值对的JSON对象，键(key)是字段(field)或属性(property)的名字，值(value)可以是字符串、数字、波尔类型、另一个对象、值数组或者其他特殊类型，比如表示日期的字符串或者表示地理位置的对象。

对象(Object)。是一个JSON结构体——类似于哈希、hashmap、字典或者关联数组；对象(Object)中还可能包含其他对象(Object)。

文档(document)。它特指最顶层结构或者根对象(root object)序列化成的JSON数据（以唯一ID标识并
存储于Elasticsearch中）。

#### 文档元数据(metadata)
_index 文档存储的地方
_type 文档代表的对象的类
_id 文档的唯一标识


索引(index):类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。
类型(type):相同类的对象存储在一个表里，因为它们有着相同的结构。
ID:唯一标识一个文档


### 索引一个文档

#### 指定ID增加文档 [PUT]
使用PUT方法
```
PUT /{index}/{type}/{id}
{
"field": "value",
...
}
```
#### 自增ID  [POST]
使用POST方法
```
POST /website/blog/
{
"title": "My second blog entry",
"text": "Still trying this out...",
"date": "2014/01/01"
}
```
### 检索文档 [GET]
?pretty 格式化美化输出
```
# 检索文档
GET /website/blog/123?pretty
# 检索文档中的部分_source
GET /website/blog/123/_source
```

### 检查文档是否存在
```
# 检查命令
curl -i -XHEAD http://localhost:9200/website/blog/123
# 成功返回值
HTTP/1.1 200 OK
# 失败返回值
HTTP/1.1 404 Not Found
```

### 更新整个文档 [PUT]

```
PUT /website/blog/123
{
"title": "My first blog entry",
"text": "I am starting to get the hang of this...",
"date": "2014/01/02"
}
```
文档更新后版本_version增加,旧文档标志删除状态，待空间不足时自动清理。

### 创建新文档

```
# 创建指定ID文档

PUT /website/blog/123?op_type=create
{ ... }
或
PUT /website/blog/123/_create
{ ... }
```
如果文档已经存在，则返回409，document already exists的错误

### 删除文档 [delete]

DELETE /website/blog/123
delete /* # 删除所有索引等  [不能轻易使用]
若删除时未找到文档，文档的_version也会增加。


_version：它确保在多节点间不同操作
可以有正确的顺序。

### 处理冲突 [version参数控制]
整个文档(whole document)

Elasticsearch中只存储最后被索引的任何文档，如果其他人同时也修改了这个文档，他们的修改将会丢失。

**悲观并发控制（Pessimistic concurrency control）**
这在关系型数据库中被广泛的使用，假设冲突的更改经常发生，为了解决冲突我们把访问区块化。典型的例子是在读一行数据前锁定这行，然后确保只有加锁的那个线程可以修改这行数据。
**乐观并发控制（Optimistic concurrency control）：**
被Elasticsearch使用，假设冲突不经常发生，也不区块化访问，然而，如果在读写过程中数据发生了变化，更新操作将失败。这时候由程序决定在失败后如何解决冲突。实际情况中，可以重新尝试更新，刷新数据（重新读取）或者直接反馈给用
户。


通过指定_version来修改文档，避免冲突。
```
PUT /website/blog/1?version=1 
{
"title": "My first blog entry",
"text": "Starting to get the hang of this..."
}
```

所有更新和删除文档的请求都接受 version 参数，它可以允许在你的代码中增加乐观锁控制。


### 使用外部版本控制系统
一种常见的结构是使用一些其他的数据库做为主数据库，然后使用Elasticsearch搜索数据，这意味着所有主数据库发生变化，就要将其拷贝到Elasticsearch中。如果有多个进程负责这些数据的同步，就会遇到上面提到的并发问题。

如果主数据库有版本字段——或一些类似于 timestamp等可以用于版本控制的字段——是你就可以在Elasticsearch的查询字符串后面添加 version_type=external 来使用这些版本号。版本号必须是整数，大于零小于 9.2e+18 ——Java中的正的 long 。


es版本小于外部版本时可以更新，外部版本优先：
外部版本号与之前说的内部版本号在处理的时候有些不同。它不再检查 _version是否与请求中指定的一致，而是检查是否小于指定的版本。如果请求成功，外部版本号就会被存储到 _version 中。


外部版本号不仅在索引和删除请求中指定，也可以在创建(create)新文档中指定。


PUT /website/blog/2?version=5&version_type=external
{
"title": "My first external blog entry",
"text": "Starting to get the hang of this..."
}

### 文档局部更新 [POST _update tags]

**存在字段覆盖，新字段被添加。**

最简单的 update 请求表单接受一个局部文档参数 doc ，它会合并到现有文档中——对象合并在一起，存在的标量字段被覆盖，新字段被添加。举个例子，我们可以使用以下请求为博客添加一个 tags 字段和一个 views 字段：
```
POST /website/blog/1/_update
{
"doc" : {
"tags" : [ "testing" ],
"views": 0
}
}
```

使用脚本局部更新
>使用Groovy脚本
>这时候当API不能满足要求时，Elasticsearch允许你使用脚本实现自己的逻辑。脚本支持非常多的API，例如搜索、排序、聚合和文档更新。脚本可以通过请求的一部分、检索特殊的 .scripts 索引或者从磁盘加载方式执行。
>默认的脚本语言是Groovy，一个快速且功能丰富的脚本语言，语法类似于Javascript。它在一个沙盒(sandbox)中运行，以防止恶意用户毁坏Elasticsearch或攻击服务器。

```
# 更新原有字段views 自动+1，类似自增长序列
POST /website/blog/1/_update
{
"script" : "ctx._source.views+=1"
}

# 新增字段 new_tag 自动+1，类似自增长序列
POST /website/blog/1/_update
{
"script" : "ctx._source.tags+=new_tag",
"params" : {
"new_tag" : "search"
}
}
```

通过设置 ctx.op 为 delete 我们可以根据内容删除文档：
```
POST /website/blog/1/_update
{
"script" : "ctx.op = ctx._source.views == count ? 'delete' : 'none'",
"params" : {
"count": 1
}
}
```

更新可能不存在的文档时会更新失败。




检索(retrieve)和重建索引(reindex)避免更新时数据丢失



可以通过 retry_on_conflict 参数设置重试次数来自动完成，这样 update 操作将会在发生错误前重试——这个值默认为0。
```
POST /website/pageviews/1/_update?retry_on_conflict=5 <1>
{
"script" : "ctx._source.views+=1",
"upsert": {
"views": 0
}
}
```
<1> 在错误发生前重试更新5次


### 检索多个索引中的多个文档 [multi-get mget]


不同索引中搜索 多个文档
```
GET /_mget
{
"docs" : [
{
"_index" : "website",
"_type" : "blog",
"_id" : 2
},
{
"_index" : "website",
"_type" : "pageviews",
"_id" : 1,
"_source": "views"
}
]
}
```
同一索引中搜索 多个文档
```
GET /website/_mget
{
"docs" : [
{ "_id" : 2 },
{ "_type" : "pageviews", "_id" : 1 }
]
}
```
同一索引,同一类型中搜索 多个文档
```
GET /website/blog/_mget
{
"ids" : [ "2", "1" ]
}
```
无论是否搜索到了数据，HTTP请求状态码还是 200。因为请求成功了。
如果想知道每个文档是否都成功了，你需要检查返回的 found 标志。


### 更省时的批量操作 [bulk]



bulk API允许我们使用单一请求来实现多个文档的 create 、 index 、 update 或 delete.



bulk 请求体如下，它有一点不同寻常：
{ action: { metadata }}\n
{ request body }\n
{ action: { metadata }}\n
{ request body }\n
...
这种格式类似于用 "\n" 符号连接起来的一行一行的**JSON文档流(stream)**。两个重要的点需要注意：
- 每行必须以 "\n" 符号结尾，包括最后一行。这些都是作为每行有效的分离而做的标记。
- 每一行的数据不能包含未被转义的换行符，它们会干扰分析——这意味着JSON不能被美化打印。




action/metadata这一行定义了文档行为(what action)发生在哪个文档(which document)之上。
行为(action)必须是以下几种：

行为|解释
create |当文档不存在时创建之。详见《创建文档》
index |创建新文档或替换已有文档。见《索引文档》和《更新文档》
update |局部更新文档。见《局部更新》
delete |删除一个文档。见《删除文档》
 
在索引、创建、更新或删除时必须指定文档的 _index 、 _type 、 _id 这些元数据(metadata)。

```
# 删除请求
{ "delete": { "_index": "website", "_type": "blog", "_id": "123" }}
```

请求体(request body)由文档的 _source 组成——文档所包含的一些字段以及其值。它被 index 和 create 操作所必须，这是有道理的：你必须提供文档用来索引。


这些还被 update 操作所必需，而且请求体的组成应该与 update API（ doc , upsert , script 等等）一致。删除操作不需要请求体(request body)。


Elasticsearch响应包含一个 items 数组，它罗列了每一个请求的结果，结果的顺序与我们请求的顺序相同：


这些说明 bulk 请求不是原子操作——它们不能实现事务。每个请求操作时分开的，所以每个请求的成功与否不干扰其它操作。




#### 不要重复
你可能在同一个 index 下的同一个 type 里批量索引日志数据。为每个文档指定相同的元数据是多余的。就像 mget
API， bulk 请求也可以在URL中使用 /_index 或 /_index/_type :
POST /website/_bulk
{ "index": { "_type": "log" }}
{ "event": "User logged in" }
你依旧可以覆盖元数据行的 _index 和 _type ，在没有覆盖时它会使用URL中的值作为默认值：
POST /website/log/_bulk
{ "index": {}}
{ "event": "User logged in" }
{ "index": { "_type": "blog" }}
{ "title": "Overriding the default type" }




#### 多大才算太大？
整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的内存就越小。有一个最佳的 bulk 请求大小。超过这个大小，性能不再提升而且可能降低。

最佳点(sweetspot)，当然并不是一个固定的数字。它完全取决于你的硬件、你文档的大小和复杂度以及索引和搜索的负载。


- 物理大小：在5-15MB大小间。
- 文档数量大小：1000~5000个文档之间 




## 分布式增删改查
这一章我们深入这些内部细节来帮助你更好的理解数据是如何在分布式系统中存储的。

pass


## 搜索


映射(Mapping) 数据在每个字段中的解释说明
分析(Analysis) 全文是如何处理的可以被搜索的
领域特定语言查询(Query DSL) Elasticsearch使用的灵活的、强大的查询语言


### 空搜索(empty search)
GET /_search

响应中最重要的部分是 hits  ，它包含了 total  字段来表示匹配到的文档总数， hits  数组还包含了匹配到的前10条数据。


 _score 相关性得分(relevance score)，衡量了文档与查询的匹配程度。默认的，返回的结
果中关联性最大的文档排在首位；这意味着，它是按照 _score  降序排列的。这种情况下，我们没有指定任何查询，所以所有
文档的相关性是一样的，因此所有结果的 _score  都是取得一个中间值 1


max_score  指的是所有文档匹配查询中 _score  的最大值。


took  告诉我们整个搜索请求花费的毫秒数。

_shards  节点告诉我们参与查询的分片数（ total  字段），有多少是成功的（ successful  字段），有多少的是失败的
（ failed  字段）

time_out  值告诉我们查询超时与否。一般的，搜索请求不会超时。如果响应速度比完整的结果更重要，你可以定
义 timeout  参数为 10  或者 10ms  （10毫秒），或者 1s  （1秒）


### 多索引和多类别
/_search 在所有索引的所有类型中搜索
/gb/_search 在索引 gb 的所有类型中搜索
/gb,us/_search 在索引 gb  和 us  的所有类型中搜索
/g*,u*/_search 在以 g  或 u  开头的索引的所有类型中搜索
/gb/user/_search 在索引 gb  的类型 user  中搜索
/gb,us/user,tweet/_search 在索引 gb  和 us  的类型为 user  和 tweet  中搜索
/_all/user,tweet/_search 在所有索引的 user  和 tweet  中搜索 search types  user  and  tweet  in all indices

## 分页

size  : 每页条数，默认 10
from  : 跳过开始的结果数，默认 0

在分布式系统中，排序结果的花费随着分页的深入而成倍增长。这也是为什么网络搜索引擎中任何语句不能返回多于1000个结果的原因。




简易搜索

查询字符串(query string)将所有参数通过查询字符串定义
JSON完整的表示请求体(request body)，这种富搜索语言叫做结构化查询语句（DSL）


GET /_all/tweet/_search?q=tweet:elasticsearch

百分比编码(percent encoding)（译者注：就是url编码）需要将查询字符串参数变得更加神秘：GET /_search?q=%2Bname%3Ajohn+%2Btweet%3Amary

"+"  前缀表示语句匹配条件必须被满足。类似的 "-"  前缀表示条件必须不被满足。所有条件如果没有 +  或 -  表示是可选的——匹配越多，相关的文档就越多。

当你索引一个文档，Elasticsearch把所有字符串字段值连接起来放在一个大字符串中，它被索引为一个特殊的字段 _all ,查询字符串在其他字段被定以前使用 _all  字段搜索。

更复杂的语句

下一个搜索推特的语句：
_all  field
name  字段包含 "mary"  或 "john"
date  晚于 2014-09-10
_all  字段包含 "aggregations"  或 "geo"
+name:(mary john) +date:>2014-09-10 +(aggregations geo)
编码后的查询字符串变得不太容易阅读：
?q=%2Bname%3A(mary+john)+%2Bdate%3A%3E2014-09-10+%2B(aggregations+geo)


TIP：因为这些原因，我们不建议直接暴露查询字符串搜索给用户，除非这些用户对于你的数据和集群可信。


## 映射

### 映射&分析
映射(mapping)机制用于进行字段类型确认，将每个字段匹配为一种确定的数据类型( string  ,  number  ,  booleans  ,date  等)。
分析(analysis)机制用于进行全文文本(Full Text)的分词，以建立供搜索用的反向索引。

Elasticsearch为对字段类型进行猜测，动态生成了字段和类型的映射关系。date  类型的字段和 string 类型的字段的索引方式是不同的，因此导致查询结果的不同，这并不会让我们觉得惊讶。

你会期望每一种核心数据类型(strings, numbers, booleans及dates)以不同的方式进行索引，而这点也是现实：在Elasticsearch中他们是被区别对待的。但是更大的区别在于确切值(exact values)(比如 string  类型)及全文文本(full text)之间。这两者的区别才真的很重要 - 这是区分搜索引擎和其他数据库的根本差异。


### 确切值(Exact values) vs. 全文文本(Full text)


确切值是很容易查询的，因为结果是二进制的 -- 要么匹配，要么不匹配。

而对于全文数据的查询来说，却有些微妙。我们不会去询问 这篇文档是否匹配查询要求？  。 但是，我们会询问 这篇文档和查询的匹配程
度如何？  。换句话说，对于查询条件，这篇文档的相关性有多高？

为了方便在全文文本字段中进行这些类型的查询，Elasticsearch首先对文本分析(analyzes)，然后使用结果建立一个倒排索引。







# 项目常用命令



## 项目优化命令
autopep8自动格式化命令
autopep8 --in-place --aggressive data_pandas.py 

## 数据导入命令
数据检测
```python tools.py --check_data 201701 102 TRANJRNL```

数据载入
```time python tools.py --load_data 201701 102 TRANJRNL```

## 程序相关命令
程序关闭命令
ps ux|grep gunicorn|grep -v grep|awk '{print $2}'|xargs kill -9

项目load_data进程关闭命令
ps aux | grep python | grep load_data | awk '{print $2}' |xargs kill -9





## 删除kibana索引
delete /*

## 删除日志
delete FT_BATCH_log; 
delete ft_batch;
delete REPORT_OPERATING_LOG;
delete MODEL_TRIGGER_ENTRY;
delete REPORT;
delete MINING_BATCH_LOG;
delete MINING_BATCH;
delete cust_report;

# 项目常用命令



## 项目优化命令
autopep8自动格式化命令
autopep8 --in-place --aggressive data_pandas.py 

## 数据导入命令
数据检测
```python tools.py --check_data 201701 102 TRANJRNL```

数据载入
```time python tools.py --load_data 201701 102 TRANJRNL```

## 程序相关命令
程序关闭命令
ps ux|grep gunicorn|grep -v grep|awk '{print $2}'|xargs kill -9

项目load_data进程关闭命令
ps aux | grep python | grep load_data | awk '{print $2}' |xargs kill -9

ps aux | grep data_pandas | awk '{print $2}' |xargs kill -9

ps aux | grep python | grep start_daily | awk '{print $2}' |xargs kill -9




select * from report ;
select * from MODEL_TRIGGER_ENTRY ;

select * from MINING_BATCH order by ID  desc;


# 数据库日志表删除
## 删除报表相关信息
select * from report ;
select * from MODEL_TRIGGER_ENTRY ;








# ES


## update
更新部分文档 update_by_query


# 分析程序
python tools.py  --analysis_data 20990131 301 ALL
# 



 
2017年1月数据 -- 对比数据条数



## 查看基础指标


## 查看模型情况


## 查看报告情况







 ################# 运行时间估算

es导入：
	数据条数：2亿
	耗时：2小时

分析程序：
	数据条数：2亿
	耗时：2.5小时

指标运行：
	数据条数：2亿条  20min/一天
	运行耗时：1小时

模型运行：
	数据条数：2亿条
	运行耗时：2.5小时

总共：
	数据条数：2亿条
	运行耗时：2+2.5+9+2.5=16小时/月


##################  es测试问题

删除es日志
重启es节点
删除指标测试日，当天索引
删除red索引
开启监控文件
测试运行指标




 

#########################
自动启动操作 - 
先备份- 删除数据库日志等

删除kibana索引
delete /*

删除日志
delete FT_BATCH_log; 
delete ft_batch;
delete REPORT_OPERATING_LOG;
delete MODEL_TRIGGER_ENTRY;
-- report表数据report_no和MODEL_TRIGGER_ENTRY关联。
delete REPORT;  
delete MINING_BATCH_LOG;
delete MINING_BATCH;

### 删除指定report中数据

-- 删除索引约束表数据
delete from model_trigger_entry
where report_no in (
select report_no from report
where TRIGGER_MODEL_NO = 'T1'
and  ISSUE_DATE >= to_date('2017-05-01','YYYY-mm-dd') and ISSUE_DATE < to_date('2017-08-01','YYYY-mm-dd') ;
--and report_no='81110';
)
;

-- 删除report
delete from report
where TRIGGER_MODEL_NO = 'T1'
and ISSUE_DATE >= to_date('2017-05-01','YYYY-mm-dd') and ISSUE_DATE < to_date('2017-08-01','YYYY-mm-dd') ;





#### 将内存不足等情况加入监控警报
ll /var/log/messages
grep -rin "Kill process" /var/log/messages


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>. sql

select * from report;

k1 恐怖融资监控模型
k2 境外ATM取现异常恐怖融资监控
T1 特殊节日异常监控
k3 防回流涉恐模型
P1 地下钱庄
;

update report set TRIGGER_MODEL_NAME='恐怖融资监控模型' where TRIGGER_MODEL_NO='K1' ;
update report set TRIGGER_MODEL_NAME='境外ATM取现异常恐怖融资监控' where TRIGGER_MODEL_NO='K2' ;
update report set TRIGGER_MODEL_NAME='特殊节日异常监控' where TRIGGER_MODEL_NO='T1' ;
update report set TRIGGER_MODEL_NAME='防回流涉恐模型' where TRIGGER_MODEL_NO='K3' ;
update report set TRIGGER_MODEL_NAME='地下钱庄' where TRIGGER_MODEL_NO='P1' ;

;
select * from MINING_MODEL;


select 
b.MODEL_NAME,
from report a
left join MINING_MODEL b on a.TRIGGER_MODEL_NO = b.MODEL_NO
;

 



select * from report ;


select * from report where  TRIGGER_MODEL_NO = 'K3';


select * from BACK_MINING_MODEL_ENTITY;

select  * from MINING_BATCH
where model_no='T1' and "01-" in minning_date
order by END_DT desc 
;

-- 删除手动挖掘的数据
select * from MINING_BATCH where BATCH_type='挖掘'; 
select distinct BATCH_type from MINING_BATCH;
select * from MINING_BATCH_log  where BATCH_ID in ( select ID from MINING_BATCH where BATCH_type='挖掘');

delete from  MINING_BATCH_log  where BATCH_ID in ( select ID from MINING_BATCH where BATCH_type='挖掘');
delete from MINING_BATCH where BATCH_type='挖掘'; 
 

-- 查看用户操作情况
select * from web_log 
where OPERATOR in ('001','002','003')
order by id desc ;

select * from web_log 
--where OPERATOR in ('001','002','003')
order by id desc ;
;

select * from MINING_MODEL_ENTITY 
where ENTITY_NO like 'Z%'

;

select * from MINING_MODEL_ENTITY 
where ENTITY_NO='Z021003'
 order by ENTITY_NO ;






select * from MINING_MODEL_ENTITY
where entity_no='Z021002';

select * from report ;




---- 统计模型中报告数量
--select count(1) from (
select TRIGGER_MODEL_NO,count(1) from report 
where 1=1
and TRIGGER_MODEL_NO='T1'
and  ISSUE_DATE >= to_date('2017-04-01','YYYY-mm-dd') and ISSUE_DATE < to_date('2017-05-01','YYYY-mm-dd') 
--)
group by TRIGGER_MODEL_NO
;

select * from report 
where 1=1
and TRIGGER_MODEL_NO='K1'
and  ISSUE_DATE >= to_date('2017-05-01','YYYY-mm-dd') and ISSUE_DATE < to_date('2017-06-01','YYYY-mm-dd') 
;

select * from cust_report
where CERT_NO
in 
(
select cert_no from report 
where 1=1
and TRIGGER_MODEL_NO='K1'
and  ISSUE_DATE >= to_date('2017-05-01','YYYY-mm-dd') and ISSUE_DATE < to_date('2017-06-01','YYYY-mm-dd') 
)
;
 
 
 select * from web_log
 --where REMARK like '%2017%'
  where LOG_TYPE = '运行'
 order by OPER_TIME desc ；
 
 ;
select * from MINING_BATCH 
order by START_DT desc ;



select * from report
order by REPT_DATE desc ;


select * from report
order by report_no desc 
;
 
where  BATCH_ID in

（
select id from MINING_BATCH
where BATCH_TYPE='挖掘'  
and OPERATOR='001'
and MINING_DATE >= to_date('2015-01-01','YYYY-mm-dd') and MINING_DATE < to_date('2015-05-01','YYYY-mm-dd') 
)
;


select * from report 
order by REPT_DATE desc ;


select * from cust_report ;




select * from MINING_BATCH 
where BATCH_TYPE='模型自动'
order by START_DT desc 

;




 select * form REPORT; 


 -- 改成分析员
select * from  MINING_BATCH
where MINING_DATE >=  to_date('2015-01-20','YYYY-mm-dd') and MINING_DATE < to_date('2017-08-20','YYYY-mm-dd') 
--and id in ('3634', '3632', '3629', '3626', '3624', '3621', '3618', '3615', '3613', '3610', '3608', '3606', '3603', '3602','3644', '3643', '3641', '3639', '3637', '3601')
and id in ('3657', '3656', '3655', '3654', '3653', '3652', '3651', '3650', '3649', '3648', '3647', '3645', '3644', '3643', '3641', '3639', '3637')
and BATCH_TYPE='模型自动'
order by START_DT desc ;



-- 改成分析员 更新 MINING_BATCH
update   MINING_BATCH set OPERATOR_CODE='001',OPERATOR='001',BATCH_TYPE='挖掘'
where 1=1
--MINING_DATE >=  to_date('2016-06-20','YYYY-mm-dd') and MINING_DATE < to_date('2017-08-20','YYYY-mm-dd') 
--and id in ('3634', '3632', '3629', '3626', '3624', '3621', '3618', '3615', '3613', '3610', '3608', '3606', '3603', '3602','3644', '3643', '3641', '3639', '3637', '3601')
and id in ('3657', '3656', '3655', '3654', '3653', '3652', '3651', '3650', '3649', '3648', '3647', '3645', '3644', '3643', '3641', '3639', '3637')
;
-- 更新 report 
update report set REPT_TYPE='挖掘' 
where 1=1
and batch_id in ('3657', '3656', '3655', '3654', '3653', '3652', '3651', '3650', '3649', '3648', '3647', '3645', '3644', '3643', '3641', '3639', '3637') ;
;
--batch_id in ('3634', '3632', '3629', '3626', '3624', '3621', '3618', '3615', '3613', '3610', '3608', '3606', '3603', '3602','3644', '3643', '3641', '3639', '3637', '3601') ;

-- 更新运行查询报告
-- nosetests -sv fdm/mining/test.py

select * from MINING_BATCH
order by START_DT desc ;


select * from report 
where
cert_no='653223198103031113'
 --ISSUE_DATE=to_date('2016-12-10','YYYY-MM-dd')
order by  REPT_DATE desc ;

3645
3645;

delete from model_trigger_entry where REPORT_NO in ('84277') ;




-- 统计挖掘的命中客户数量
select  ISSUE_MONTH,CERT_NO,CUST_NAME,count(1) from cust_report 
where REPT_TYPE='挖掘'
group by ISSUE_MONTH,CERT_NO,CUST_NAME
order by ISSUE_MONTH,CERT_NO,CUST_NAME  desc ;



select * from cust_report
where cert_no='653101197503244814'  ;


select * from cust_report order by ID desc ;


select distinct cert_no from cust_report  where id > '2884605' ;




select * from cust_report ;


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ES


# 查询指定日期范围和指定模糊匹配字段数据
GET /tranjrnl-*-2017-03-31/_search
{
  "_source": "TRAN_SUMMARY",
  "size": 20,
  "query": {
    "constant_score": {
      "filter": {
        "bool": {
          "must": [
            {
              "terms": {
                "TRAN_SUMMARY": [
                  "息"
                ]
              }
            },
            {
              "range": {
                "TRAN_DATE": {
                  "from": "2017-03-21",
                  "to": "2017-03-21"
                }
              }
            }
          ]
        }
      }
    }
  }
}




# 查询索引所有数据
GET /tranjrnl-*-2016-03-31/_search
{
  "query": {
    "match_all": {}
  }
}

# 聚合 group by
GET /tranjrnl-*-2017-03-31/_search
{
  "size": 0,
  "aggs": {
    "JY_JXZY": {
      "terms": {
        "field": "JY_JXZY"
      }
    }
  }
}
 
### where条件下的group by 
GET /tranjrnl-*102*-2017-03-31/_search
{
  "size": 0,
  "query": {
    "constant_score": {
      "filter": {
        "bool": {
          "must": [
            {
              "range": {
                "TRAN_DATE": {
                  "from": "2017-03-21",
                  "to": "2017-03-21"
                }
              }
            }
          ]
        }
      }
    }
  },
  "aggs": {
    "all_groupby": {
      "terms": {
        "field": "TRAN_TYPE"
      }
    }
  }
}

# 索引删除
DELETE /.monitori*
delete /.kibana*
delete /.watche*
delete /.trigg*
  
curl -XDELETE 'http://192.168.172.70:9200/.monitori*' 
curl -XDELETE 'http://192.168.172.70:9200/.kibana*' 
curl -XDELETE 'http://192.168.172.70:9202/.watche*' 
curl -XDELETE 'http://192.168.172.70:9200/.trigg*' 
 

 
# 短语精准匹配
GET /tranjrnl-01020000-2017-03-31/_search
{
  "query": {
    "match_phrase": {
      "content":{
        "query":"息"
    }
  }
}
}
  
# 短语精准匹配
GET /tranjrnl-*-2017-03-31/_search
{

  "query": {
    "query_string": {
      "query": "0",
      "fields": [
        "interest"
      ]
    }
  }
}





 


### match匹配 + 日期区间选择
GET /tranjrnl-*103*-2017-03-31/_search
{
  "size": 100,
  "_source": "TRAN_SUMMARY",
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "TRAN_SUMMARY": "结息"
          }
        }
      ],
      "filter": {
        "bool": {
          "must": [
            {
              "range": {
                "TRAN_DATE": {
                  "from": "2017-03-21",
                  "to": "2017-03-21"
                }
              }
            }
          ]
        }
      }
    }
  }
}
   
        
### terms匹配 + 日期区间选择        
GET /tranjrnl-*103*-2017-03-31/_search
{
  "size": 20,
  "query": { 
    "constant_score": { 
      "filter": { 
        "bool": { 
          "must": [ 
            {
              "range": { 
                "TRAN_DATE": { 
                  "from": "2017-03-21",
                  "to": "2017-03-21"
                }
              }
            },
            {
              "term": { 
                "TRAN_SUMMARY": "结"
              }
            },
            {
              "term": { 
                "TRAN_SUMMARY": "息"
              }
            }
          ]
        }
      }
    }
  }
}               
        
        





# ES跑批常见问题 TODO 重要




此下为ES跑批





